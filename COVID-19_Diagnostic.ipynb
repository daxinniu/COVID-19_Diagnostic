{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"COVID-19_Diagnostic.ipynb","provenance":[{"file_id":"13K2JGzhObXHh0CnfBoGvzyCaG4ASlgD8","timestamp":1615396587824}],"collapsed_sections":[],"machine_shape":"hm"},"file_extension":".py","kernelspec":{"display_name":"Python 3","name":"python3"},"mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"cells":[{"cell_type":"markdown","metadata":{"id":"WSMO2e0Ca3tU"},"source":["## **COVID-19 Diagnosis Using Chest X-Ray Data**\n","This project uses Chest X-Ray Data to train a deep neural network to help diagnose COVID-19."]},{"cell_type":"markdown","metadata":{"id":"n_Kecj9IbFCT"},"source":["### Introduction\n","COVID-19 is severely impacting the health of countless people worldwide. A crucial step in controlling the disease has been early detection of infected patients, which can be achieved through radiography, according to prior literature that shows COVID-19 causes chest abnormalities noticeable in chest X-rays."]},{"cell_type":"markdown","metadata":{"id":"u3tF64VybOiZ"},"source":["We begin by importing necessary packages for our model.\n"]},{"cell_type":"code","metadata":{"id":"ZKzt0tiAbYLY","executionInfo":{"status":"ok","timestamp":1638304729045,"user_tz":300,"elapsed":194,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}}},"source":["import cv2\n","import os\n","import numpy as np\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zd6HN-95LqYr"},"source":["###Data Collection\n","There is no substantially-sized, clinically verified, and publicly available COVID-19 dataset. However, a small composite dataset with X-Rays of COVID-19 positive patients recently became publicly available with [DeepCovid](https://github.com/shervinmin/DeepCovid), which compiled their data from:\n","\n","[Covid-Chestxray-Dataset](https://github.com/ieee8023/covid-chestxray-dataset) for COVID-19 X-ray samples\n","\n","[ChexPert Dataset](https://stanfordmlgroup.github.io/competitions/chexpert/) for Non-COVID samples\n"]},{"cell_type":"markdown","metadata":{"id":"zUMj440wKo7L"},"source":["Our data was stored on a google drive so we will mount the drive to get the data"]},{"cell_type":"code","metadata":{"id":"4VyDyG1pJHZ9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638304729247,"user_tz":300,"elapsed":3,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}},"outputId":"e9387ea9-f039-4ccf-9c34-a01b1ae3ca9e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"GaQiCm9YJbw0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638304732331,"user_tz":300,"elapsed":3085,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}},"outputId":"d17fcb84-455a-458f-973b-a538e3fea026"},"source":["from zipfile import ZipFile\n","\n","file_name = 'drive/My Drive/dataset.zip'\n","\n","with ZipFile(file_name, 'r') as zip:\n","    zip.extractall()\n","    print(\"Data extracted!\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Data extracted!\n"]}]},{"cell_type":"markdown","metadata":{"id":"4VmIvYDDRJR6"},"source":["Next, let us begin feature and label building. We can utilize Paths to \n","list the directory of every X-Ray from the dataset."]},{"cell_type":"code","metadata":{"id":"rO_jTgD5H1Zo","executionInfo":{"status":"ok","timestamp":1638304739535,"user_tz":300,"elapsed":7207,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}}},"source":["from imutils import paths\n","\n","data = []\n","labels = []\n","\n","# Grab list of image paths using paths.list_images\n","imagePaths = list(paths.list_images('data_upload_v3/train/covid')) + list(paths.list_images('data_upload_v3/train/non'))\n","\n","# Label and resize the images \n","\n","for imagePath in imagePaths:\n","\t# extract the class label from the filename\n","    if imagePath[21] == 'c':\n","\t    label = 'covid'\n","    else:\n","        label = 'normal'\n","\n","    image = cv2.imread(imagePath)\n","    image = cv2.resize(image, (224, 224))\n","\n","    data.append(image)\n","    labels.append(label)\n","\n","\n","# Convert data and labels to a Numpy Array and normalize the pixel values\n","data = np.array(data) / 255.0\n","labels = np.array(labels)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m4_xQFmdt8Vz","executionInfo":{"status":"ok","timestamp":1638304739536,"user_tz":300,"elapsed":22,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}},"outputId":"06bcb33b-a211-45ca-87ee-c98e3805b18b"},"source":["(unique, counts) = np.unique(labels, return_counts=True)\n","frequencies = np.asarray((unique, counts)).T\n","print(frequencies)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[['covid' '84']\n"," ['normal' '2000']]\n"]}]},{"cell_type":"code","metadata":{"id":"tobHh4Pisnh5","executionInfo":{"status":"ok","timestamp":1638305172838,"user_tz":300,"elapsed":12725,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}}},"source":["# Extract test data\n","\n","test_data = []\n","test_labels = []\n","\n","# Grab list of image paths using paths.list_images\n","test_imagePaths = list(paths.list_images('data_upload_v3/test/covid')) + list(paths.list_images('data_upload_v3/test/non'))\n","\n","# Label and resize the images \n","\n","for imagePath in test_imagePaths:\n","\t# extract the class label from the filename\n","    if imagePath[20] == 'c':\n","\t    label = 'covid'\n","    else:\n","        label = 'normal'\n","\n","    image = cv2.imread(imagePath)\n","    image = cv2.resize(image, (224, 224))\n","\n","    test_data.append(image)\n","    test_labels.append(label)\n","\n","\n","# Convert data and labels to a Numpy Array and normalize the pixel values\n","test_data = np.array(test_data) / 255.0\n","test_labels = np.array(test_labels)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XtIZSW3Jkc2y","executionInfo":{"status":"ok","timestamp":1638305175158,"user_tz":300,"elapsed":162,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}},"outputId":"4def6431-bad3-49f9-ec1b-f9932c5eeaa8"},"source":["(unique, counts) = np.unique(test_labels, return_counts=True)\n","frequencies = np.asarray((unique, counts)).T\n","print(frequencies)"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["[['covid' '100']\n"," ['normal' '3000']]\n"]}]},{"cell_type":"markdown","metadata":{"id":"n3zmzxdQd9ON"},"source":["Use SKLearn to one-hot encode our labels."]},{"cell_type":"code","metadata":{"id":"0J2yOK7md_y6","executionInfo":{"status":"ok","timestamp":1638305176995,"user_tz":300,"elapsed":170,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}}},"source":["from sklearn.preprocessing import LabelBinarizer\n","from tensorflow.keras.utils import to_categorical\n","\n","lb = LabelBinarizer()\n","labels = lb.fit_transform(labels)\n","labels = to_categorical(labels)\n","test_labels = lb.fit_transform(test_labels)\n","test_labels = to_categorical(test_labels)"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bHZEuVVDeBv9"},"source":["### Data Splitting\n","Now that we're done grabbing our data, we can begin to look at splitting the data into our training and validation sets."]},{"cell_type":"code","metadata":{"id":"FK0h4tnQeH56","executionInfo":{"status":"ok","timestamp":1638304753215,"user_tz":300,"elapsed":801,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}}},"source":["from sklearn.model_selection import train_test_split\n","# Partition data into 80% training and 20% validation\n","\n","trainX, testX, trainY, testY = train_test_split(data, labels, stratify=labels,test_size = 0.20, random_state=123)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_echi_0APEis"},"source":["### Set hyperparameters"]},{"cell_type":"code","metadata":{"id":"FweemVCFPH9c","executionInfo":{"status":"ok","timestamp":1638304753215,"user_tz":300,"elapsed":6,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}}},"source":["EPOCHS = 20\n","BATCH_SIZE = 16\n","LR = 1e-4"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YByvq-9oRwn_"},"source":["### Base model\n","We are gonna use ResNet as the base model. The pretrained weights come from imagenet, and our input is (224,224,3)."]},{"cell_type":"code","metadata":{"id":"InLljPNaeYI2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638304761064,"user_tz":300,"elapsed":7852,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}},"outputId":"4fcee031-1ac0-42ee-b981-5f9756fbdbc5"},"source":["from tensorflow.keras.applications import ResNet152V2\n","from tensorflow.keras.layers import Input\n","\n","base = ResNet152V2(include_top=False, weights = 'imagenet', input_shape = (224,224,3))"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","234553344/234545216 [==============================] - 2s 0us/step\n","234561536/234545216 [==============================] - 2s 0us/step\n"]}]},{"cell_type":"markdown","metadata":{"id":"B571TxNMebs_"},"source":["###Build Model###\n","We will construct our model here."]},{"cell_type":"code","metadata":{"id":"9B6da8LIehJ-","executionInfo":{"status":"ok","timestamp":1638304761064,"user_tz":300,"elapsed":4,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}}},"source":["from tensorflow.keras.layers import AveragePooling2D\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.metrics import AUC\n","from keras.losses import categorical_crossentropy\n","\n","#Construct structure after ResNet\n","head = base.output\n","head = AveragePooling2D(pool_size=(7,7))(head)\n","head = BatchNormalization()(head)\n","head = Flatten()(head)\n","head = Dense(128, activation='relu')(head)\n","head = Dense(2, activation='sigmoid')(head)\n","\n","# Combine the model\n","model = Model(inputs=base.input, outputs=head)\n","\n","# Freeze base layers\n","base.trainable = False\n","\n","# Compile the model\n","model.compile(loss=categorical_crossentropy, optimizer=Adam(learning_rate = LR), metrics=[AUC(curve=\"PR\")])"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0SoyFWCZeLe0"},"source":["### Data augmentation\n","Use data augmentation object for our training set to make the model more robust."]},{"cell_type":"code","metadata":{"id":"kzi3yvZYeSOy","executionInfo":{"status":"ok","timestamp":1638304761065,"user_tz":300,"elapsed":4,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","trainAug = ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True\n",")"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ataiZOiKe5du"},"source":["###Training\n"]},{"cell_type":"code","metadata":{"id":"cn-dHilyW5X9","executionInfo":{"status":"ok","timestamp":1638304761065,"user_tz":300,"elapsed":4,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}}},"source":["# Add Earlystopping to monitor validation loss\n","from tensorflow.keras.callbacks import EarlyStopping\n","callback = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 5)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"MpiC-2O3e780","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638305141699,"user_tz":300,"elapsed":380637,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}},"outputId":"41bfe1fd-8dbf-4ef6-fe76-e54f13d6e92b"},"source":["# Train model\n","H = model.fit(\n","    trainAug.flow(trainX, trainY, batch_size=BATCH_SIZE), \n","    validation_data = (testX, testY), \n","    steps_per_epoch=len(trainX) // BATCH_SIZE, \n","    epochs = EPOCHS,\n","    callbacks = [callback]\n",")"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","104/104 [==============================] - 36s 201ms/step - loss: 0.3640 - auc: 0.8517 - val_loss: 0.1713 - val_auc: 0.9760\n","Epoch 2/20\n","104/104 [==============================] - 18s 172ms/step - loss: 0.1512 - auc: 0.9684 - val_loss: 0.1324 - val_auc: 0.9840\n","Epoch 3/20\n","104/104 [==============================] - 18s 175ms/step - loss: 0.1135 - auc: 0.9816 - val_loss: 0.1024 - val_auc: 0.9885\n","Epoch 4/20\n","104/104 [==============================] - 18s 174ms/step - loss: 0.0946 - auc: 0.9883 - val_loss: 0.0873 - val_auc: 0.9911\n","Epoch 5/20\n","104/104 [==============================] - 18s 174ms/step - loss: 0.0745 - auc: 0.9907 - val_loss: 0.0741 - val_auc: 0.9935\n","Epoch 6/20\n","104/104 [==============================] - 18s 173ms/step - loss: 0.0661 - auc: 0.9918 - val_loss: 0.0630 - val_auc: 0.9953\n","Epoch 7/20\n","104/104 [==============================] - 18s 174ms/step - loss: 0.0591 - auc: 0.9941 - val_loss: 0.0601 - val_auc: 0.9958\n","Epoch 8/20\n","104/104 [==============================] - 18s 173ms/step - loss: 0.0558 - auc: 0.9951 - val_loss: 0.0520 - val_auc: 0.9968\n","Epoch 9/20\n","104/104 [==============================] - 18s 173ms/step - loss: 0.0513 - auc: 0.9957 - val_loss: 0.0523 - val_auc: 0.9967\n","Epoch 10/20\n","104/104 [==============================] - 18s 172ms/step - loss: 0.0420 - auc: 0.9970 - val_loss: 0.0455 - val_auc: 0.9975\n","Epoch 11/20\n","104/104 [==============================] - 18s 173ms/step - loss: 0.0461 - auc: 0.9965 - val_loss: 0.0517 - val_auc: 0.9970\n","Epoch 12/20\n","104/104 [==============================] - 18s 174ms/step - loss: 0.0393 - auc: 0.9976 - val_loss: 0.0507 - val_auc: 0.9975\n","Epoch 13/20\n","104/104 [==============================] - 18s 173ms/step - loss: 0.0509 - auc: 0.9961 - val_loss: 0.0514 - val_auc: 0.9975\n","Epoch 14/20\n","104/104 [==============================] - 18s 172ms/step - loss: 0.0319 - auc: 0.9983 - val_loss: 0.0494 - val_auc: 0.9976\n","Epoch 15/20\n","104/104 [==============================] - 18s 175ms/step - loss: 0.0377 - auc: 0.9975 - val_loss: 0.0421 - val_auc: 0.9982\n","Epoch 16/20\n","104/104 [==============================] - 18s 176ms/step - loss: 0.0418 - auc: 0.9975 - val_loss: 0.0390 - val_auc: 0.9984\n","Epoch 17/20\n","104/104 [==============================] - 18s 173ms/step - loss: 0.0315 - auc: 0.9982 - val_loss: 0.0354 - val_auc: 0.9986\n","Epoch 18/20\n","104/104 [==============================] - 18s 171ms/step - loss: 0.0318 - auc: 0.9983 - val_loss: 0.0345 - val_auc: 0.9987\n","Epoch 19/20\n","104/104 [==============================] - 18s 172ms/step - loss: 0.0235 - auc: 0.9989 - val_loss: 0.0308 - val_auc: 0.9990\n","Epoch 20/20\n","104/104 [==============================] - 18s 173ms/step - loss: 0.0279 - auc: 0.9983 - val_loss: 0.0289 - val_auc: 0.9988\n"]}]},{"cell_type":"markdown","metadata":{"id":"-3I-K36we9tb"},"source":["### Predictions\n","Here are some important metrics to see how well our model performs on the test set."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BeAFOFuX6ixE","executionInfo":{"status":"ok","timestamp":1638305199960,"user_tz":300,"elapsed":16359,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}},"outputId":"87f54c32-e6b5-4131-fe5f-e94f939a9797"},"source":["model.evaluate(test_data, test_labels)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["97/97 [==============================] - 13s 134ms/step - loss: 0.0420 - auc: 0.9973\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.041956089437007904, 0.9973402619361877]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"6mCKD5H_fEqi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638305209488,"user_tz":300,"elapsed":4581,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}},"outputId":"8a48f57b-3881-4f9f-86f5-9e463cda02bf"},"source":["from sklearn.metrics import classification_report\n","\n","predIdxs = np.argmax(model.predict(testX, batch_size=BATCH_SIZE), axis=1)\n","\n","print(classification_report(testY.argmax(axis=1), predIdxs,\n","\ttarget_names=lb.classes_))"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       covid       0.93      0.76      0.84        17\n","      normal       0.99      1.00      0.99       400\n","\n","    accuracy                           0.99       417\n","   macro avg       0.96      0.88      0.92       417\n","weighted avg       0.99      0.99      0.99       417\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"irgvVeEJ5vfs","executionInfo":{"status":"ok","timestamp":1638305224719,"user_tz":300,"elapsed":15241,"user":{"displayName":"Daxin Niu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi0tgVh9lroul4cj-lkayJFBCJyxhSKif2sV9PnqA=s64","userId":"17158397741899558228"}},"outputId":"8c117afd-68bc-4f9d-add3-239161e139d3"},"source":["predIdxs = np.argmax(model.predict(test_data, batch_size=BATCH_SIZE), axis=1)\n","\n","print(classification_report(test_labels.argmax(axis=1), predIdxs,\n","\ttarget_names=lb.classes_))"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       covid       0.93      0.66      0.77       100\n","      normal       0.99      1.00      0.99      3000\n","\n","    accuracy                           0.99      3100\n","   macro avg       0.96      0.83      0.88      3100\n","weighted avg       0.99      0.99      0.99      3100\n","\n"]}]}]}